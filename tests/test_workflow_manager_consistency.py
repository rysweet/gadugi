#!/usr/bin/env python3
"""
Comprehensive tests for WorkflowManager consistency and Phase 9 enforcement.

Tests the new enforcement mechanisms to ensure:
1. Phase 9 (code review) is never skipped
2. Execution continues after planning (no early termination)
3. Orphaned PR detection and recovery works
4. State consistency validation works
5. Automatic phase transitions work
"""

import json
import pytest
import tempfile
import unittest
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import Mock, patch, MagicMock, call
import subprocess
import os
import time


# Test fixtures and utilities
class MockGitHubPR:
    def __init__(
        self,
        number,
        title,
        author="test-user",
        has_reviews=False,
        created_minutes_ago=0,
    ):
        self.number = number
        self.title = title
        self.author = author
        self.has_reviews = has_reviews
        self.created_at = (
            datetime.now() - timedelta(minutes=created_minutes_ago)
        ).isoformat()
        self.reviews = [{"author": {"login": "code-reviewer"}}] if has_reviews else []

    def to_gh_json(self):
        """Convert to GitHub CLI JSON format"""
        return {
            "number": self.number,
            "title": self.title,
            "author": {"login": self.author},
            "createdAt": self.created_at,
            "reviews": self.reviews,
        }


class MockWorkflowState:
    def __init__(
        self,
        task_id="test-task-123",
        phase_8_complete=False,
        phase_9_complete=False,
        pr_number=None,
    ):
        self.task_id = task_id
        self.phase_8_complete = phase_8_complete
        self.phase_9_complete = phase_9_complete
        self.pr_number = pr_number

    def to_state_file_content(self):
        """Generate state file content"""
        phase_8_status = "[x]" if self.phase_8_complete else "[ ]"
        phase_9_status = "[x]" if self.phase_9_complete else "[ ]"
        pr_line = f"- **PR Number**: #{self.pr_number}" if self.pr_number else ""

        return f"""# WorkflowManager State
Task ID: {self.task_id}
Last Updated: {datetime.now().isoformat()}

## Phase Completion Status
- [x] Phase 1: Initial Setup ‚úÖ
- [x] Phase 2: Issue Creation ‚úÖ
- [x] Phase 3: Branch Management ‚úÖ
- [x] Phase 4: Research and Planning ‚úÖ
- [x] Phase 5: Implementation ‚úÖ
- [x] Phase 6: Testing ‚úÖ
- [x] Phase 7: Documentation ‚úÖ
- {phase_8_status} Phase 8: Pull Request
- {phase_9_status} Phase 9: Review

## Active Workflow
{pr_line}

## PR Information
PR #{self.pr_number}: Test Implementation
"""


class TestPhase9Enforcement(unittest.TestCase):
    """Test Phase 9 enforcement mechanisms"""

    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.mock_pr_number = 123

    def tearDown(self):
        # Clean up temp files
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    @patch("subprocess.run")
    def test_phase_9_automatic_invocation_after_pr_creation(self, mock_subprocess):
        """Test that Phase 9 is automatically invoked 30 seconds after PR creation"""

        # Mock successful PR creation
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = (
            f"https://github.com/test/repo/pull/{self.mock_pr_number}"
        )

        # Mock the enforcement mechanism
        with patch("time.sleep") as mock_sleep:
            with patch("os.system") as mock_system:
                # Simulate Phase 8 completion triggering Phase 9
                os.environ["PR_NUMBER"] = str(self.mock_pr_number)
                os.environ["PHASE_9_ENFORCEMENT"] = "true"

                # This would be the actual enforcement logic
                if os.environ.get("PHASE_9_ENFORCEMENT") == "true":
                    mock_sleep.assert_not_called()  # Will be called in actual implementation
                    # Verify that code-reviewer would be invoked
                    expected_command = "/agent:code-reviewer"

                # Verify enforcement flag is set
                self.assertEqual(os.environ.get("PHASE_9_ENFORCEMENT"), "true")
                self.assertEqual(os.environ.get("PR_NUMBER"), str(self.mock_pr_number))

    @patch("subprocess.run")
    def test_phase_9_state_validation_before_completion(self, mock_subprocess):
        """Test that workflow cannot complete without Phase 9 validation"""

        # Mock gh pr view command to return no reviews
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = '{"reviews": []}'

        # Test the validation function logic
        def verify_phase_9_completion(pr_number):
            result = subprocess.run(
                ["gh", "pr", "view", str(pr_number), "--json", "reviews"],
                capture_output=True,
                text=True,
            )

            if result.returncode != 0:
                return False

            reviews_data = json.loads(result.stdout)
            return len(reviews_data.get("reviews", [])) > 0

        # Test with no reviews (should fail validation)
        self.assertFalse(verify_phase_9_completion(self.mock_pr_number))

        # Mock gh pr view command to return reviews
        mock_subprocess.return_value.stdout = (
            '{"reviews": [{"author": {"login": "code-reviewer"}}]}'
        )

        # Test with reviews (should pass validation)
        self.assertTrue(verify_phase_9_completion(self.mock_pr_number))

    def test_enhanced_task_list_requirements(self):
        """Test that Phase 9 and 10 tasks are always included with high priority"""

        # Mock task list generation
        def generate_workflow_tasks():
            tasks = [
                # Standard tasks 1-8...
                {
                    "id": "9",
                    "content": "üö® MANDATORY: Invoke code-reviewer agent (Phase 9 - CANNOT SKIP)",
                    "status": "pending",
                    "priority": "high",
                    "phase": "REVIEW",
                    "auto_invoke": True,
                    "enforcement_level": "CRITICAL",
                },
                {
                    "id": "10",
                    "content": "üö® MANDATORY: Process review with code-review-response agent",
                    "status": "pending",
                    "priority": "high",
                    "phase": "REVIEW_RESPONSE",
                    "auto_invoke": True,
                    "enforcement_level": "CRITICAL",
                },
            ]
            return tasks

        tasks = generate_workflow_tasks()

        # Verify Phase 9 task
        phase_9_task = next((task for task in tasks if task["id"] == "9"), None)
        self.assertIsNotNone(phase_9_task)
        self.assertEqual(phase_9_task["priority"], "high")
        self.assertTrue(phase_9_task["auto_invoke"])
        self.assertEqual(phase_9_task["enforcement_level"], "CRITICAL")
        self.assertIn("MANDATORY", phase_9_task["content"])
        self.assertIn("CANNOT SKIP", phase_9_task["content"])

        # Verify Phase 10 task
        phase_10_task = next((task for task in tasks if task["id"] == "10"), None)
        self.assertIsNotNone(phase_10_task)
        self.assertEqual(phase_10_task["priority"], "high")
        self.assertTrue(phase_10_task["auto_invoke"])
        self.assertEqual(phase_10_task["enforcement_level"], "CRITICAL")
        self.assertIn("MANDATORY", phase_10_task["content"])

    @patch("subprocess.run")
    def test_automatic_phase_transitions(self, mock_subprocess):
        """Test that Phase 8‚Üí9 and Phase 9‚Üí10 transitions are automatic"""

        # Mock successful operations
        mock_subprocess.return_value.returncode = 0

        with patch("time.sleep") as mock_sleep:
            with patch("os.system") as mock_system:
                # Test Phase 8 ‚Üí Phase 9 transition (30-second delay)
                def simulate_phase_8_completion():
                    print("‚úÖ Phase 8 complete: PR #123 created")
                    print("‚è±Ô∏è  Starting 30-second countdown to Phase 9...")
                    time.sleep(30)  # This would be mocked
                    print("üö® AUTOMATIC Phase 9 execution starting NOW")
                    return True

                # Test Phase 9 ‚Üí Phase 10 transition (immediate)
                def simulate_phase_9_completion():
                    print("‚úÖ Code review posted successfully")
                    print("‚ö° IMMEDIATE Phase 10 execution starting NOW")
                    return True

                # Verify transitions would happen
                self.assertTrue(simulate_phase_8_completion())
                self.assertTrue(simulate_phase_9_completion())


class TestExecutionCompletion(unittest.TestCase):
    """Test execution completion requirements and anti-termination safeguards"""

    def test_execution_commitment_requirements(self):
        """Test that all execution commitment requirements are met"""

        # Mock prompt file validation
        def validate_prompt_structure(prompt_file):
            if not os.path.exists(prompt_file):
                raise FileNotFoundError("Prompt file not found")
            return True

        # Create a test prompt file
        with tempfile.NamedTemporaryFile(
            mode="w", suffix=".md", delete=False
        ) as temp_prompt:
            temp_prompt.write("""# Test Prompt
## Overview
Test prompt for validation
## Problem Statement
Test problem
## Implementation Plan
Test plan
## Success Criteria
Test criteria
""")
            temp_prompt_path = temp_prompt.name

        try:
            # Test prompt validation
            self.assertTrue(validate_prompt_structure(temp_prompt_path))

            # Test that invalid paths raise errors
            with self.assertRaises(FileNotFoundError):
                validate_prompt_structure("/nonexistent/prompt.md")

        finally:
            os.unlink(temp_prompt_path)

    def test_anti_termination_safeguards(self):
        """Test that anti-termination safeguards prevent early exits"""

        # Define safeguard checks
        safeguards = {
            "stop_after_planning": False,  # Must not stop after Phase 4
            "wait_for_user_confirmation": False,  # Must not wait between phases
            "skip_phase_9_or_10": False,  # Must not skip mandatory phases
            "complete_without_review": False,  # Must validate Phase 9
            "terminate_on_recoverable_errors": False,  # Must retry recoverable errors
        }

        # Test that all safeguards are properly configured
        for safeguard, should_be_disabled in safeguards.items():
            self.assertFalse(
                should_be_disabled, f"Safeguard {safeguard} must be disabled"
            )

    def test_progress_verification_checkpoints(self):
        """Test progress verification checkpoints after each phase"""

        def verify_phase_artifacts(phase, **kwargs):
            """Mock artifact verification"""
            artifacts = {
                2: "issue_number",
                3: "branch_name",
                8: "pr_number",
                9: "review_posted",
                10: "review_response_posted",
            }

            if phase in artifacts:
                required_artifact = artifacts[phase]
                return (
                    required_artifact in kwargs
                    and kwargs[required_artifact] is not None
                )

            return True

        # Test each checkpoint
        self.assertTrue(verify_phase_artifacts(2, issue_number=123))
        self.assertTrue(verify_phase_artifacts(3, branch_name="feature/test"))
        self.assertTrue(verify_phase_artifacts(8, pr_number=456))
        self.assertTrue(verify_phase_artifacts(9, review_posted=True))
        self.assertTrue(verify_phase_artifacts(10, review_response_posted=True))

        # Test failure cases
        self.assertFalse(verify_phase_artifacts(2, issue_number=None))
        self.assertFalse(verify_phase_artifacts(8, pr_number=None))

    def test_execution_flow_guarantee(self):
        """Test the guaranteed execution pattern"""

        # Define the expected execution flow
        expected_phases = [
            "Parse prompt",
            "Generate task list",
            "START EXECUTION IMMEDIATELY",
            "Phase 1-4: Setup, Issue, Branch, Research/Planning",
            "Phase 5-7: Implementation, Testing, Documentation",
            "Phase 8: PR Creation",
            "30-second timer",
            "AUTOMATIC Phase 9",
            "Phase 9: Code Review",
            "Verification",
            "IMMEDIATE Phase 10",
            "Phase 10: Review Response",
            "Final state update",
            "COMPLETE",
        ]

        # Mock execution tracker
        executed_phases = []

        def execute_phase(phase_name):
            executed_phases.append(phase_name)
            return True

        # Simulate execution flow
        for phase in expected_phases:
            execute_phase(phase)

        # Verify all phases were executed
        self.assertEqual(len(executed_phases), len(expected_phases))
        self.assertIn("AUTOMATIC Phase 9", executed_phases)
        self.assertIn("IMMEDIATE Phase 10", executed_phases)


class TestOrphanedPRDetection(unittest.TestCase):
    """Test orphaned PR detection and recovery mechanisms"""

    def setUp(self):
        self.script_path = (
            "/Users/ryan/src/gadugi3/gadugi/.claude/utils/orphaned_pr_recovery.sh"
        )

    @patch("subprocess.run")
    def test_orphaned_pr_detection(self, mock_subprocess):
        """Test detection of PRs without reviews older than threshold"""

        # Mock GitHub CLI response with orphaned PRs
        orphaned_prs = [
            MockGitHubPR(
                101, "Feature Implementation", created_minutes_ago=10, has_reviews=False
            ),
            MockGitHubPR(
                102, "Bug Fix Implementation", created_minutes_ago=6, has_reviews=False
            ),
            MockGitHubPR(
                103, "Recent PR", created_minutes_ago=2, has_reviews=False
            ),  # Too recent
            MockGitHubPR(
                104, "PR with Review", created_minutes_ago=10, has_reviews=True
            ),  # Has review
        ]

        # Mock gh pr list command
        gh_response = json.dumps([pr.to_gh_json() for pr in orphaned_prs])
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = gh_response

        # Test detection logic (simplified)
        def detect_orphaned_prs(max_age_minutes=5):
            # Parse GitHub response
            prs_data = json.loads(gh_response)
            threshold_time = datetime.now() - timedelta(minutes=max_age_minutes)

            orphaned = []
            for pr in prs_data:
                pr_time = datetime.fromisoformat(pr["createdAt"].replace("Z", "+00:00"))
                if pr_time < threshold_time and len(pr["reviews"]) == 0:
                    orphaned.append(pr["number"])

            return orphaned

        # Should detect PRs 101 and 102 (older than 5 minutes, no reviews)
        orphaned = detect_orphaned_prs(max_age_minutes=5)
        self.assertIn(101, orphaned)
        self.assertIn(102, orphaned)
        self.assertNotIn(103, orphaned)  # Too recent
        self.assertNotIn(104, orphaned)  # Has review

    def test_orphaned_pr_recovery_script_exists(self):
        """Test that the orphaned PR recovery script exists and is executable"""

        self.assertTrue(
            os.path.exists(self.script_path), "Orphaned PR recovery script should exist"
        )
        self.assertTrue(
            os.access(self.script_path, os.X_OK), "Script should be executable"
        )

    @patch("subprocess.run")
    def test_workflow_pr_identification(self, mock_subprocess):
        """Test identification of PRs that were created by WorkflowManager"""

        def is_workflow_pr(pr_title, pr_body=""):
            """Mock workflow PR identification logic"""
            import re

            # Check for AI-generated markers
            ai_markers = ["Generated with.*Claude Code", "AI agent"]
            for marker in ai_markers:
                if re.search(marker, pr_body, re.IGNORECASE):
                    return True

            # Check title patterns
            workflow_patterns = [
                "Implementation",
                "Feature.*Implementation",
                "Fix.*Implementation",
            ]
            for pattern in workflow_patterns:
                if re.search(pattern, pr_title, re.IGNORECASE):
                    return True

            return False

        # Test various PR titles and bodies
        test_cases = [
            ("Feature Implementation", "", True),
            ("Bug Fix Implementation", "", True),
            ("Manual PR", "", False),
            ("Regular PR", "Generated with Claude Code", True),
            ("Another PR", "Created by AI agent", True),
            ("Documentation Update", "", False),
        ]

        for title, body, expected in test_cases:
            with self.subTest(title=title):
                self.assertEqual(is_workflow_pr(title, body), expected)


class TestStateConsistencyValidation(unittest.TestCase):
    """Test state consistency validation and auto-correction"""

    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()
        self.state_file = os.path.join(self.temp_dir, "state.md")

    def tearDown(self):
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_phase_8_complete_but_not_marked(self):
        """Test auto-correction when PR exists but Phase 8 not marked complete"""

        # Create state file with PR but Phase 8 not marked complete
        state = MockWorkflowState(pr_number=123, phase_8_complete=False)
        with open(self.state_file, "w") as f:
            f.write(state.to_state_file_content())

        # Test validation and auto-correction
        def validate_and_fix_phase_8_state(state_file_path):
            with open(state_file_path, "r") as f:
                content = f.read()

            # Check if PR exists but Phase 8 not marked complete
            if "PR #" in content and "[ ] Phase 8:" in content:
                # Auto-fix by marking Phase 8 complete
                content = content.replace("[ ] Phase 8:", "[x] Phase 8:")

                with open(state_file_path, "w") as f:
                    f.write(content)

                return True, "Auto-fixed Phase 8 state"

            return False, "No fix needed"

        # Test the fix
        fixed, message = validate_and_fix_phase_8_state(self.state_file)
        self.assertTrue(fixed)
        self.assertEqual(message, "Auto-fixed Phase 8 state")

        # Verify the fix was applied
        with open(self.state_file, "r") as f:
            content = f.read()
        self.assertIn("[x] Phase 8:", content)
        self.assertNotIn("[ ] Phase 8:", content)

    @patch("subprocess.run")
    def test_phase_8_complete_but_no_review(self, mock_subprocess):
        """Test detection when Phase 8 complete but no review exists"""

        # Mock no reviews found
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = '{"reviews": []}'

        # Create state file with Phase 8 complete but no Phase 9
        state = MockWorkflowState(
            pr_number=123, phase_8_complete=True, phase_9_complete=False
        )
        with open(self.state_file, "w") as f:
            f.write(state.to_state_file_content())

        # Test validation logic
        def validate_phase_9_consistency(state_file_path):
            with open(state_file_path, "r") as f:
                content = f.read()

            # Check if Phase 8 complete but no Phase 9
            if "[x] Phase 8:" in content and "[ ] Phase 9:" in content:
                # Extract PR number
                import re

                pr_match = re.search(r"PR #(\d+)", content)
                if pr_match:
                    pr_number = pr_match.group(1)

                    # Check if PR has reviews
                    result = subprocess.run(
                        ["gh", "pr", "view", pr_number, "--json", "reviews"],
                        capture_output=True,
                        text=True,
                    )

                    if result.returncode == 0:
                        reviews_data = json.loads(result.stdout)
                        if len(reviews_data.get("reviews", [])) == 0:
                            return (
                                True,
                                f"CRITICAL: Phase 8 complete but no review for PR #{pr_number}",
                            )

            return False, "State is consistent"

        # Test the validation
        needs_fix, message = validate_phase_9_consistency(self.state_file)
        self.assertTrue(needs_fix)
        self.assertIn("CRITICAL", message)
        self.assertIn("no review", message)


class TestIntegrationScenarios(unittest.TestCase):
    """Integration tests for complete workflow scenarios"""

    @patch("subprocess.run")
    @patch("time.sleep")
    @patch("os.system")
    def test_complete_workflow_with_phase_9_enforcement(
        self, mock_system, mock_sleep, mock_subprocess
    ):
        """Test complete workflow execution with Phase 9 enforcement"""

        # Mock successful operations
        mock_subprocess.return_value.returncode = 0
        mock_subprocess.return_value.stdout = '{"reviews": []}'  # Initially no reviews

        # Simulate workflow execution
        workflow_phases = []

        def execute_workflow_phase(phase_num, phase_name):
            workflow_phases.append((phase_num, phase_name))

            # Special handling for Phase 8 ‚Üí Phase 9 transition
            if phase_num == 8:
                # PR created, trigger Phase 9 enforcement
                mock_sleep(30)  # 30-second timer
                execute_workflow_phase(9, "Review")
                execute_workflow_phase(10, "Review Response")

            return True

        # Execute phases 1-8
        for i in range(1, 9):
            phase_name = [
                "Setup",
                "Issue",
                "Branch",
                "Research",
                "Implementation",
                "Testing",
                "Documentation",
                "PR",
            ][i - 1]
            execute_workflow_phase(i, phase_name)

        # Verify all phases were executed
        self.assertEqual(len(workflow_phases), 10)  # All phases including 9 and 10

        # Verify Phase 9 and 10 were executed
        phase_numbers = [phase[0] for phase in workflow_phases]
        self.assertIn(9, phase_numbers)
        self.assertIn(10, phase_numbers)

        # Verify automatic execution (sleep was called for 30-second timer)
        mock_sleep.assert_called_with(30)


if __name__ == "__main__":
    # Run all tests
    unittest.main(verbosity=2)
